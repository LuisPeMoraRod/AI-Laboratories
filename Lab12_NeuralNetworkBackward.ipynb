{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisPeMoraRod/AI-Laboratories/blob/main/Lab12_NeuralNetworkBackward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejercicio 3"
      ],
      "metadata": {
        "id": "P1YGwgYS2Vcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import exp\n",
        "import numpy as np\n",
        "\n",
        "# Initialize a network using class example as reference\n",
        "def initialize_network():\n",
        "    network = list()\n",
        "    # 2 neurons in hidden layer\n",
        "    bias1 = 0.35\n",
        "    hidden_layer = [{'weights':[0.15, 0.25, bias1]}, {'weights':[0.2, 0.3, bias1]}]\n",
        "    network.append(hidden_layer)\n",
        "\n",
        "    # 2 neurons output layer\n",
        "    bias2 = 0.6\n",
        "    output_layer = [{'weights':[0.4, 0.5, bias2]}, {'weights':[0.45, 0.55, bias2]}]\n",
        "    network.append(output_layer)\n",
        "    return network\n",
        "\n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        "\n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        "\n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        "\n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "\n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']\n",
        "\n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, expected, l_rate, n_epoch, tol):\n",
        "    outputs = list()\n",
        "    for _ in range(n_epoch):\n",
        "        sum_error = 0\n",
        "        for row in train:\n",
        "            outputs_i = forward_propagate(network, row)\n",
        "            outputs.append(outputs_i)\n",
        "            sum_error += sum([0.5*(expected[i]-outputs_i[i])**2 for i in range(len(expected))])\n",
        "            backward_propagate_error(network, expected)\n",
        "            update_weights(network, row, l_rate)\n",
        "        if (abs(sum_error) < tol):\n",
        "            break\n",
        "    return outputs\n",
        "\n",
        "# Test training backprop algorithm\n",
        "dataset = [[0.05, 0.1]]\n",
        "expected = [0.01, 0.99]\n",
        "network = initialize_network()\n",
        "\n",
        "alpha = 0.5\n",
        "max_iters = 10000\n",
        "tol = 1e-5\n",
        "outputs = train_network(network, dataset, expected, alpha, max_iters, tol)\n",
        "\n",
        "hidden_layer = network[0]\n",
        "output_layer = network[1]\n",
        "\n",
        "h1 = hidden_layer[0]\n",
        "h2 = hidden_layer[1]\n",
        "o1 = output_layer[0]\n",
        "o2 = output_layer[1]\n",
        "\n",
        "w1 = h1['weights'][0]\n",
        "w2 = h1['weights'][1]\n",
        "w3 = h2['weights'][0]\n",
        "w4 = h2['weights'][1]\n",
        "w5 = o1['weights'][0]\n",
        "w6 = o1['weights'][1]\n",
        "w7 = o2['weights'][0]\n",
        "w8 = o2['weights'][1]\n",
        "\n",
        "first_o1 = outputs[0][0]\n",
        "first_o2 = outputs[0][1]\n",
        "last_o1 = outputs[-1][0]\n",
        "last_o2 = outputs[-1][1]\n",
        "\n",
        "print(f'First iteration: \\n\\t output1 = {first_o1}, output2 = {first_o2}')\n",
        "print(f'Last iteration (n = {len(outputs)-1}): \\n\\t output1 = {last_o1}, output2 = {last_o2}')\n",
        "\n",
        "print(f'\\nHidden layer: \\n\\tw1 = {w1}, w2 = {w2} \\n\\tw3 = {w3}, w4 = {w4}')\n",
        "print(f'Output layer: \\n\\tw5 = {w5}, w6 = {w6} \\n\\tw7 = {w7}, w8 = {w8}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZZ7te2WmKw9",
        "outputId": "e68cdb53-b857-4ac8-83c5-633942cc18cb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First iteration: \n",
            "\t output1 = 0.7569319154399385, output2 = 0.7677178798069613\n",
            "Last iteration (n = 6047): \n",
            "\t output1 = 0.013201450341820496, output2 = 0.9868786195879152\n",
            "\n",
            "Hidden layer: \n",
            "\tw1 = 0.18090462464969917, w2 = 0.25 \n",
            "\tw3 = 0.22936101373817488, w4 = 0.3\n",
            "Output layer: \n",
            "\tw5 = -1.4276542042895422, w6 = -1.318473602965025 \n",
            "\tw7 = 1.4495238306748184, w8 = 1.5431112511817486\n"
          ]
        }
      ]
    }
  ]
}